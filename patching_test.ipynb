{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[  4.6257,  -1.6788,   0.6811,  -1.2430,  -3.0429,  -1.4799,   1.8272,\n",
      "           0.3229,  -0.6663,   1.9405,   3.2772,   3.7112,  -2.3815,   1.5453,\n",
      "          -0.2690,  -3.1102],\n",
      "        [ 65.2144, -59.3474,  15.1797, -52.5843, -25.5713, -50.0275,  49.5692,\n",
      "          45.9517,   8.1941,  24.4910,  63.1394,  61.5667, -41.0966,  -2.5194,\n",
      "         -61.3413, -19.2633]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([2, 16])\n",
      "tensor([  4.6257,  -1.6788,   0.6811,  -1.2430,  -3.0429,  -1.4799,   1.8272,\n",
      "          0.3229,  -0.6663,   1.9405,   3.2772,   3.7112,  -2.3815,   1.5453,\n",
      "         -0.2690,  -3.1102,  65.2144, -59.3474,  15.1797, -52.5843, -25.5713,\n",
      "        -50.0275,  49.5692,  45.9517,   8.1941,  24.4910,  63.1394,  61.5667,\n",
      "        -41.0966,  -2.5194, -61.3413, -19.2633], grad_fn=<ViewBackward0>)\n",
      "tensor([ 12.0544, -17.0241,  -1.4515,  -7.6158,  20.6663,  24.7793, -11.2734,\n",
      "         -6.9495, -20.3165,  22.7216,  -8.7802, -12.1654, -20.6531, -14.2307,\n",
      "         18.3421,  33.3302,   1.4174,  -7.0083,  27.6850, -15.3095, -14.9084,\n",
      "         -1.9906, -11.5583,  -7.8955,  26.6895,  15.7003, -26.8177,  16.3737,\n",
      "         10.9468, -24.2288, -10.9935,  -4.5783], grad_fn=<AddBackward0>)\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# idea 1, 2 stages patching\n",
    "\n",
    "test_input = torch.tensor([[5,2,3], [123,4,7]]).float()   #shape (2,3)\n",
    "\n",
    "print(test_input.shape)\n",
    "\n",
    "# each patch into embedding\n",
    "\n",
    "d_model = 32\n",
    "d_patch = 16\n",
    "\n",
    "w_patch_indv = torch.nn.Linear(test_input.shape[1], d_patch)\n",
    "\n",
    "x = w_patch_indv(test_input)\n",
    "\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "#flatten channels\n",
    "\n",
    "x = x.view(-1)\n",
    "\n",
    "print(x)\n",
    "\n",
    "\n",
    "\n",
    "# merge each channels into the patches\n",
    "\n",
    "w_channel_m = torch.nn.Linear(x.shape[0], d_model)\n",
    "\n",
    "x = w_channel_m(x)\n",
    "\n",
    "print(x)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_1_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
