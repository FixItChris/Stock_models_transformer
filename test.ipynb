{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1, 1)\n",
      "[-0.24318472 -0.10326846  0.14551774  0.09388182  0.16411474  0.09579294\n",
      "  0.08957873 -0.23152643 -0.16371813  0.00643662  0.04437798  0.08180664\n",
      "  0.16832884  0.50132424  0.14367586]\n",
      "[-0.28807533  0.2936211   0.84149134  0.04105194  0.12143223  0.17425466\n",
      " -0.6780516  -0.12085529 -1.0155877  -1.124596    0.01754558  0.44627866\n",
      "  2.3314888   0.33241615  1.5396876 ]\n"
     ]
    }
   ],
   "source": [
    "pred_data = np.load(r'results\\stock_000001SZustd_50_1_PatchTST_stock_custom_ftMS_sl50_ll25_pl1_dm128_nh8_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0\\pred.npy')\n",
    "print(pred_data.shape)\n",
    "pred_data = pred_data.reshape((pred_data.shape[0]))\n",
    "print(pred_data[:15])\n",
    "\n",
    "true_data = np.load(r'results\\stock_000001SZustd_50_1_PatchTST_stock_custom_ftMS_sl50_ll25_pl1_dm128_nh8_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0\\true.npy')\n",
    "true_data = true_data.reshape((true_data.shape[0]))\n",
    "print(true_data[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vincent\\.conda\\envs\\Pytorch_1_11\\lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#load scaler\n",
    "with open(r'scaler\\stock_000001SZustd\\stock_000001SZustd_50_1.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10)\n"
     ]
    }
   ],
   "source": [
    "tc =  np.load('scaler\\stock_000001SZustd\\stock_000001SZustd_50_1.npy')\n",
    "print(tc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n",
      "[-0.24318472 -0.10326846  0.14551774  0.09388182  0.16411474  0.09579294\n",
      "  0.08957873 -0.23152643 -0.16371813  0.00643662]\n"
     ]
    }
   ],
   "source": [
    "print(pred_data.shape)\n",
    "print(pred_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 9)\n",
      "(800, 10)\n"
     ]
    }
   ],
   "source": [
    "pred_tmp_t = np.full((pred_data.shape[0], 9), 0, np.float32)\n",
    "print(pred_tmp_t.shape)\n",
    "pred_tmp_t = np.insert(pred_tmp_t, 9, pred_data, axis=1)\n",
    "print(pred_tmp_t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5323521  -0.16628733  0.48461524  0.3495195   0.53327084  0.3545196\n",
      "  0.33826125 -0.50185037 -0.32444263  0.12073547]\n"
     ]
    }
   ],
   "source": [
    "#get the orginal \n",
    "pred_orig = scaler.inverse_transform(pred_tmp_t)[:,-1]\n",
    "print(pred_orig[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_inverse(label_c, original_dimension, original_position, scaler): #original dimensino(2D) without the label_c column\n",
    "    temp_matrix = np.full(original_dimension, 0, np.float32)\n",
    "    temp_matrix = np.insert(temp_matrix, original_position, label_c, axis=1)\n",
    "    return scaler.inverse_transform(temp_matrix)[:, original_position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pred_orig[:10] == data_inverse(pred_data, (pred_data.shape[0], 9), 9, scaler)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n",
      "[[ 3.6099999e+00  1.0841413e+05  6.7332305e+04 -2.2471910e+00\n",
      "   1.4354067e+00 -1.6722408e-01  4.2919999e-01  4.2918077e-01\n",
      "  -3.1142139e+00 -2.5605137e+00]\n",
      " [-1.9000000e+00  1.0686837e+05  6.6813688e+04  3.1198688e+00\n",
      "   6.2893081e-01  2.5125628e+00 -1.2294000e+00 -1.2293609e+00\n",
      "   6.9516301e-01  4.1986537e-01]\n",
      " [ 0.0000000e+00  7.9396477e+04  4.9387039e+04 -1.5923567e+00\n",
      "  -9.3750000e-01  3.2679740e-01 -1.7776000e+00 -1.7775663e+00\n",
      "  -1.3017663e+00 -1.8708645e+00]\n",
      " [-2.7500000e+00  1.1148138e+05  6.7292188e+04  1.6181229e-01\n",
      "  -1.5772871e+00 -3.9087949e+00  1.9450000e-01  1.9450904e-01\n",
      "  -1.8292873e+00 -1.7309900e-01]\n",
      " [-1.9900000e+00  5.4461621e+04  3.2003586e+04 -2.7463651e+00\n",
      "  -3.5256410e+00 -2.3728814e+00 -1.3827000e+00 -1.3826935e+00\n",
      "   2.1324158e-01 -1.4597582e+00]]\n",
      "(4139, 10)\n",
      "float32\n",
      "(4139,)\n"
     ]
    }
   ],
   "source": [
    "true_y = data_inverse(true_data, (true_data.shape[0], 9), 9, scaler)\n",
    "print(true_y.shape)\n",
    "\n",
    "A_x = np.genfromtxt('PatchTST_supervised\\stock_data\\stock_000001SZustd.csv', delimiter=',', skip_header=1)\n",
    "A_x = A_x.astype(np.float32)\n",
    "A_x = A_x[: , 1:]\n",
    "print(A_x[:5])\n",
    "print(A_x.shape)\n",
    "print(A_x.dtype)\n",
    "print(A_x[:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subset_pos(A, B):\n",
    "    print(A.shape)\n",
    "    print(B.shape)\n",
    "    for i in range(A.shape[0] - B.shape[0] + 1):\n",
    "        if np.array_equal(A[i:i+B.shape[0]], B):\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4139,)\n",
      "(800,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_subset_pos(A_x[:, 1].astype(np.int16), true_y.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_subset_pos(np.array([1,2,3,4]), np.array([4.2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd date time\n",
    "\n",
    "s1 = pd.read_csv(r'PatchTST_supervised\\stock_data\\stock_000001SZustd.csv')\n",
    "format_string = '%Y%m%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = pd.to_datetime(s1.date, format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts3 = pd.to_datetime(s1.date, format=format_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2005-05-10\n",
       "1      2005-05-11\n",
       "2      2005-05-12\n",
       "3      2005-05-13\n",
       "4      2005-05-16\n",
       "          ...    \n",
       "4134   2022-12-09\n",
       "4135   2022-12-12\n",
       "4136   2022-12-13\n",
       "4137   2022-12-14\n",
       "4138   2022-12-15\n",
       "Name: date, Length: 4139, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2005-05-10\n",
       "1      2005-05-11\n",
       "2      2005-05-12\n",
       "3      2005-05-13\n",
       "4      2005-05-16\n",
       "          ...    \n",
       "4134   2022-12-09\n",
       "4135   2022-12-12\n",
       "4136   2022-12-13\n",
       "4137   2022-12-14\n",
       "4138   2022-12-15\n",
       "Name: date, Length: 4139, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2 = pd.to_datetime(ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2005-05-10T00:00:00.000000000', '2005-05-11T00:00:00.000000000',\n",
       "       '2005-05-12T00:00:00.000000000', ...,\n",
       "       '2022-12-13T00:00:00.000000000', '2022-12-14T00:00:00.000000000',\n",
       "       '2022-12-15T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2005-05-10\n",
       "1      2005-05-11\n",
       "2      2005-05-12\n",
       "3      2005-05-13\n",
       "4      2005-05-16\n",
       "          ...    \n",
       "4134   2022-12-09\n",
       "4135   2022-12-12\n",
       "4136   2022-12-13\n",
       "4137   2022-12-14\n",
       "4138   2022-12-15\n",
       "Name: date, Length: 4139, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2 * Minutes>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.tseries.frequencies.to_offset('2t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_1_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
